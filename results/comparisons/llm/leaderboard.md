# LLM Toxicity Classification Leaderboard

The table below summarizes the evaluation of local and prompt-based LLM models on the combined forum comment dataset. Models are ranked primarily by **Macro F1**, reflecting balanced performance across all classes. Accuracy is also provided for reference.

This leaderboard highlights the comparative strengths of advanced reasoning models in identifying nuanced comment toxicity, with Qwen3-4b and Phi-4 demonstrating top performance.

| Rank | Model | Accuracy | Macro F1 |
|------|--------|-----------|-----------|
| 1 | qwen3-4b-thinking-2507 | 0.9565 | 0.9512 |
| 2 | phi-4-reasoning-plus | 0.9739 | 0.9429 |
| 3 | meta-llama-3.1-8b-instruct | 0.7826 | 0.8179 |